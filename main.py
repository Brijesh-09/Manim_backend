import os
import subprocess
import time
import boto3
import redis
import json
import re
import shutil
import requests

# Directories
# RENDER_DIR = "/app/render"
# OUTPUT_DIR = "/app/render/output"
# MEDIA_DIR = "/app/media/videos"

RENDER_DIR = "/tmp/render"
OUTPUT_DIR = os.path.join(RENDER_DIR, "output")
MEDIA_DIR = "/tmp/media/videos"
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(MEDIA_DIR, exist_ok=True)

# Environment Variables
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
AWS_REGION = os.getenv("AWS_REGION", "ap-south-1")
REDIS_URL = os.getenv("REDIS_URL")
BACKEND_CALLBACK_URL = os.getenv("BACKEND_CALLBACK_URL")  # e.g., https://yourdomain.com/api/video/update-url

def get_redis_client():
    try:
        return redis.from_url(REDIS_URL, decode_responses=True)
    except Exception as e:
        print(f"[ERROR] Redis connection failed: {e}")
        return None

def download_from_s3(s3_key, local_path):
    print(f"[INFO] Downloading {s3_key} from S3")
    s3 = boto3.client("s3", region_name=AWS_REGION)
    try:
        s3.download_file(S3_BUCKET_NAME, s3_key, local_path)
        print("[SUCCESS] Downloaded")
        return True
    except Exception as e:
        print(f"[ERROR] S3 download failed: {e}")
        return False

def validate_manim_script(script_path):
    try:
        with open(script_path, 'r') as f:
            content = f.read()

        # Fix common syntax issues
        content = re.sub(r'\.set_fill\(([^,]+),\s*opacity=([^)]+)\)', r'.set_fill(\1).set_opacity(\2)', content)
        content = re.sub(r'Text\(([^,]+),\s*font_size=([^)]+)\)', r'Text(\1).scale(\2/48)', content)

        with open(script_path, 'w') as f:
            f.write(content)

        return True
    except Exception as e:
        print(f"[ERROR] Script validation failed: {e}")
        return False

def render_manim_file(file_path):
    print(f"[INFO] Rendering {file_path}...")
    if not validate_manim_script(file_path):
        return False
    try:
        subprocess.run([
            "manim",
            "-ql",
            file_path,
            "AutoGeneratedScene"
        ], check=True)
        print("[SUCCESS] Render complete.")
        return True
    except subprocess.CalledProcessError as e:
        print(f"[ERROR] Manim render failed: {e}")
        return False

def find_latest_video(job_id):
    for root, dirs, files in os.walk(MEDIA_DIR):
        for file in files:
            if file.endswith(".mp4") and "AutoGeneratedScene" in file and job_id in root:
                return os.path.join(root, file)
    return None

def upload_to_s3(file_path, key):
    print(f"[INFO] Uploading {file_path} to S3 as {key}")
    s3 = boto3.client("s3", region_name=AWS_REGION)
    try:
        s3.upload_file(file_path, S3_BUCKET_NAME, key)
        print("[SUCCESS] Uploaded to S3")
        return True
    except Exception as e:
        print(f"[ERROR] S3 upload failed: {e}")
        return False

def update_job_status(redis_client, job_id, status, video_url=None):
    try:
        redis_client.hset(f"job:{job_id}", "status", status)
        redis_client.hset(f"job:{job_id}", "updatedAt", time.time())
        if video_url:
            redis_client.hset(f"job:{job_id}", "videoUrl", video_url)
        print(f"[INFO] Job {job_id} status set to {status}")
    except Exception as e:
        print(f"[ERROR] Failed to update job status: {e}")

def notify_backend(job_id, video_url):
    if not BACKEND_CALLBACK_URL:
        print("[WARN] No BACKEND_CALLBACK_URL set.")
        return False

    payload = {
    "iterationId": job_id,
    "videoUrl": video_url
}

    try:
        response = requests.post(BACKEND_CALLBACK_URL, json=payload)
        if response.status_code == 200:
            print(f"[INFO] Notified backend for job {job_id}")
            return True
        else:
            print(f"[ERROR] Backend returned {response.status_code}: {response.text}")
            return False
    except Exception as e:
        print(f"[ERROR] Backend notification failed: {e}")
        return False

def process_job(job_data, redis_client):
    job_id = job_data['jobId']
    s3_key = job_data['s3Key']

    print(f"[INFO] Processing job: {job_id}")
    update_job_status(redis_client, job_id, 'processing')

    script_path = os.path.join(RENDER_DIR, f"{job_id}.py")
    if not download_from_s3(s3_key, script_path):
        update_job_status(redis_client, job_id, 'failed')
        return False

    if not render_manim_file(script_path):
        update_job_status(redis_client, job_id, 'failed')
        return False

    output_video = find_latest_video(job_id)
    if not output_video:
        update_job_status(redis_client, job_id, 'failed')
        return False

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_name = f"{job_id}.mp4"
    output_path = os.path.join(OUTPUT_DIR, output_name)
    shutil.copy2(output_video, output_path)

    video_s3_key = f"videos/{output_name}"
    if not upload_to_s3(output_path, video_s3_key):
        update_job_status(redis_client, job_id, 'failed')
        return False

    video_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{video_s3_key}"
    update_job_status(redis_client, job_id, 'completed', video_url)
    notify_backend(job_id, video_url)

    # Cleanup
    try:
        os.remove(script_path)
        os.remove(output_path)
        job_dir = os.path.join(MEDIA_DIR, job_id)
        if os.path.exists(job_dir):
            shutil.rmtree(job_dir)
    except Exception as e:
        print(f"[WARN] Cleanup failed: {e}")

    print(f"[SUCCESS] Job {job_id} completed.")
    return True

def worker_loop():
    redis_client = get_redis_client()
    if not redis_client:
        print("[ERROR] Redis not connected. Exiting.")
        return

    print("[INFO] Worker ready. Waiting for jobs...")

    while True:
        try:
            job = redis_client.brpop('renderQueue', timeout=10)
            if job:
                job_data = json.loads(job[1])
                process_job(job_data, redis_client)
            else:
                print("[INFO] No job found. Polling...")
        except KeyboardInterrupt:
            print("[INFO] Stopping worker.")
            break
        except Exception as e:
            print(f"[ERROR] Worker crashed: {e}")
            time.sleep(5)

def main():
    if not S3_BUCKET_NAME or not REDIS_URL:
        print("[ERROR] Required environment variables are missing.")
        return

    os.makedirs(RENDER_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    print("[BOOT] Manim Worker starting...")
    worker_loop()

if __name__ == "__main__":
    main()
